---
title: "Using `itsdm` to a real species: Africa savanna elephant"
author: "Lei Song"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_document:
    theme: readable
vignette: >
  %\VignetteIndexEntry{Using itsdm to a real species: Africa savanna elephant}
  %\VignetteEngine{knitr::rmarkdown_notangle}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE,
  out.width = "100%",
  dpi = 60,
  fig.path = "itsdm-"
)
```

## Set up
```{r setup, warning=F, message=F, eval=T}
library(itsdm, quietly = T)
library(ggplot2, quietly = T)
library(dplyr, quietly = T)
select <- dplyr::select
```

## Prepare environmental variables

As an example of a package, we won't use too many complex variables. Here we use:

1. Bioclimatic variables
2. Protected area and land cover type as categorical variables.

Note that maps of the protected area and land cover types are prepared and provided in this package. You could use
`system.file` with file names to find them like the following.

```{r variables, warning=F, message=F}
library(stars)
library(rnaturalearth, quietly = T)

# Bioclimatic variables
data("mainland_africa")
bios <- worldclim2(var = 'bio',
                   bry = mainland_africa,
                   path = tempdir(),
                   nm_mark = 'africa') %>%
  st_normalize()

# Protected area
fname <- 'extdata/wdpa_africa_10min.tif'
wdpa <- system.file(fname, package = 'itsdm') %>%
  read_stars() %>% setNames('wdpa')

# Land cover
fname <- 'extdata/landcover_africa_10min.tif'
landcover <- system.file(fname, package = 'itsdm') %>%
  read_stars() %>% setNames('landcover')

# Merge them together as variable stack
variables <- do.call(c, list(split(bios, 'band'),
                             wdpa, landcover))
rm(fname, bios, wdpa, landcover)
```

## Prepare occurrence from GBIF

The official name for the African savanna elephant is Loxodonta africana (Blumenbach, 1797), which could be used to search in GBIF. According to the following reasons:

1. It is not reasonable to use the very past data.
2. The distribution of elephants is relatively stable over a short time.

We choose the most recent occurrence observations (2010 to now) with an assumption that landcover changes could be ignorable between 2010 and now.

```{r occ}
library(lubridate, quietly = T)
library(rgbif, quietly = T)

## Set the time interval for querying on GBIF
start_year <- 2010
year <- sprintf('%s,%s',  start_year, year(Sys.Date()))

# Search
nm_search <- "Loxodonta africana (Blumenbach, 1797)"
occ <- occ_search(scientificName = nm_search,
                  hasCoordinate = TRUE,
                  limit = 200000,
                  year = year,
                  hasGeospatialIssue = FALSE)
```

Even though the occurrence dataset obtained from GBIF has high quality and its API provides available options to do some screening. There are still some disturbances contained in occurrence. As a complement, we do extra steps to clean the occurrence data. The steps include:

1. Basic Geo-cleaning. For example, clean the records with impossible or incomplete coordinates. Or clean the duplicated records. We did this step using package `scrubr`.
2. Range-cleaning. Strict the records to a specific area, which is an extra step for Geo-cleaning.
3. Spatial deduction. This step is to remove duplicates at the spatial resolution of raster.
4. __Environmental cleaning__. Detect and/or drop the records with outlier environmental values. We could do this step before dimension reduction of the environmental variable because `outlier.tree` compares records with the general condition.

```{r cleaning}
library(scrubr, quietly = T)

# Basic Geo-cleaning on occurrence
occ_clean <- occ$data %>%
  select(name, decimalLongitude,
         decimalLatitude, eventDate, key) %>%
  setNames(c('name', 'longitude',
             'latitude', 'date', 'key')) %>%
  mutate(date = as.Date(date)) %>%
  dframe() %>%
  coord_impossible() %>%
  coord_incomplete() %>%
  coord_unlikely() %>%
  # Will remove more duplicates according to raster resolution
  dedup()

# Range-cleaning on occurrence
## For example, Africa savanna elephant only could appear in Africa
data("mainland_africa")
occ_clean_sf <- occ_clean %>%
  st_as_sf(coords = c('longitude', 'latitude'),
           crs = 4326)
occ_clean_sf <- st_intersection(mainland_africa, occ_clean_sf)

# Spatial deduction
occ_clean_sf <- st_rasterize(
  occ_clean_sf,
  template = variables %>% select('bio1') %>%
    mutate(bio1 = NA)) %>%
  st_xy2sfc(as_points = T) %>% st_as_sf() %>%
  select(geometry)
```

```{r, echo=F, warning=F, message=F}
# Clean
rm(start_year, year, nm_search, occ, occ_clean, mainland_africa)
```

```{r outliers, fig.align='center', fig.width=5, fig.height=5}
# Environmental-cleaning on occurrence
## We used a very high z_outliers
## It is tricky to remove environmental outliers
## because it is hard to tell if they are outliers or
## just rare records.
occ_outliers <- suspicious_env_outliers(
  occ_clean_sf,
  variables = variables,
  z_outlier = 16,
  outliers_print = 4L)
plot(occ_outliers)
```

According to the figure and the prior knowledge of the Africa savanna elephant, we decide not to drop the outliers. The outliers seem more like rare records. In addition, if they are real outliers, the later `isolation.forest` could detect them again. Now let's organize the occurrence before the next step.

```{r pts_occ, warning=F, message=F}
occ <- occ_outliers$pts_occ
rm(occ_clean_sf)
```

## Understand the correlations between variables

Function `dim_reduce` in this package allows the user to reduce the dimensions arbitrarily for numeric environmental variables based on their correlation. Thus, here we do such thing to numeric ones of `variables` and keep the categorical ones.

It is highly not recommended to merge `attributes` of `variables` to `band ` or any other dimension if there are any categorical layers in it unless you know pretty well about what you are doing. Because merging will force categorical values to change to numeric ones, you know that it is tricky to convert between factors and numbers in R.

```{r var_clean, warning=F, message=F}
# Split continuous and categorical variables
# and reduce dimensions for continuous ones
cat_vars <- c('wdpa', 'landcover')
var_cat <- variables %>% select(all_of(cat_vars))
var_con <- variables %>% select(-all_of(cat_vars))
var_con_rdc <- dim_reduce(var_con, threshold = 0.75, samples = occ)
var_con_rdc

# Put together
var_con <- var_con_rdc$img_reduced
variables <- do.call(c, list(split(var_con, 'band'), var_cat))
rm(cat_vars, var_cat, var_con, var_con_rdc)

# If you really want to merge
## At least could ensure the values are the original values
var_merge <- variables
var_merge <- var_merge %>%
  mutate(wdpa = as.integer(levels(wdpa))[wdpa],
         landcover = as.integer(levels(landcover))[landcover])
var_merge <- merge(var_merge, name = 'band')
rm(var_merge)
```

By far, the `variables` is the environmental variable stack with numeric ones with low correlation and categorical ones.

## Split occurrence to training and test

```{r occ_split}
# Make occurrences
occ <- occ %>% mutate(id = 1:nrow(.))
set.seed(11)
occ_sf <- occ %>% sample_frac(0.7)
occ_test_sf <- occ %>% filter(! id %in% occ_sf$id)
occ_sf <- occ_sf %>% select(-id)
occ_test_sf <- occ_test_sf %>% select(-id)
rm(occ)
```

Now both occurrence and environmental variables are ready to use for modeling.

## Build a `isolation_forest` species distribution model

At this step, the users could use strategies like grid search and preferred evaluation metrics to find the optimal arguments for the model. As an example, here we use a set of arguments:

- `sample_rate = 1.0`
- `ndim = 2`
- `categ_cols = c('wdpa', 'landcover')`

```{r sdm, fig.align='center', fig.width=4, fig.height=3}
# Do modeling
it_sdm <- isotree_po(occ = occ_sf,
                     occ_test = occ_test_sf,
                     variables = variables,
                     categ_vars = c('wdpa', 'landcover'),
                     sample_rate = 1.0,
                     ndim = 2,
                     seed = 10L)
```

## Visualize results

Predicted environmental suitability

```{r prediction, echo = F, fig.align='center', fig.width=5.3, fig.height=4.3}
# Compare with virtual species
ggplot() +
  geom_stars(data = it_sdm$prediction) +
  scale_fill_viridis_c('Predicted suitability',
                       na.value = 'transparent') +
  coord_equal() +
  theme_linedraw()
```

Presence-only model evaluation

```{r eval, fig.align='center', fig.width=6, fig.height=6}
# According to training dataset
# it_sdm$eval_train
# plot(it_sdm$eval_train)

# According to test dataset
it_sdm$eval_test
plot(it_sdm$eval_test)
```

## Response curves

Response curves of environmental variables show how the suitability of a variable to this species changes when its value is varied.

Marginal response curves

```{r marginal_responses, fig.align='center', fig.width=8, fig.height=8}
# Plot response curves
plot(it_sdm$marginal_responses)
```

Independent response curves

```{r independent_responses, fig.align='center', fig.width=7, fig.height=5}
plot(it_sdm$independent_responses, target_var = c('bio1', 'bio3', 'landcover'))
```

Single variable dependence curves

```{r variable_dependence, fig.align='center', fig.width=7, fig.height=7}
## Variable dependence scatter points with fitted curves made by SHAP test
plot(it_sdm$variable_dependence, smooth_span = 0.7)
```

## Variable importance

Variable importance analysis is another way to understand the relationship between environmental variables and species distribution. It also could help to improve model performance.

```{r variable_analysis, fig.align='center', fig.width=8, fig.height=8}
it_sdm$variable_analysis
```

## Presence-absence map

Use function `convert_to_pa` to convert suitability to presence-absence map.

```{r pa, fig.align='center', fig.width=8, fig.height=8}
# Convert to presence-absence map
pa_map <- convert_to_pa(it_sdm$prediction,
                        method = "logistic",
                        beta = 0.2,
                        species_prevalence = 0.2)
pa_map; plot(pa_map)
```

## Analyze variable dependence

Randomly check variable dependence with each other.

```{r var_inter_dependence, fig.align='center', fig.width=7, fig.height=5}
plot(it_sdm$variable_dependence,
     target_var = c('bio1', 'bio12', 'landcover'),
     related_var = 'bio3', smooth_span = 0)
```

## Analyze variable contribution

Sometimes, we are interested in some observations, for instance, the outliers detected in the beginning steps. According to the figure below, we can tell that these suspicious outliers are not all environmental outliers.

```{r var_contrib, fig.align='center', fig.width=7, fig.height=9}
## Analyze variable contribution for interested observations.
## For example, outliers.
var_occ <- it_sdm$var_train %>% st_drop_geometry()
var_analysis <- var_occ %>%
  slice(occ_outliers$outliers %>% pull(suspious_row))
var_contrib_outliers <- variable_contrib(
  it_sdm$model,
  var_occ,
  var_analysis)

# Plot contribution separately for each observation
## By default, it only plot the most 5 important variables for each observation
## You could change `num_features` to show more variables
plot(var_contrib_outliers, plot_each_obs = T)
```

Let's take a look at the general variable contribution.

```{r var_contrib_general, fig.align='center', fig.width=6, fig.height=5}
var_contrib <- variable_contrib(
  it_sdm$model,
  it_sdm$var_train %>% st_drop_geometry(),
  it_sdm$var_train %>% st_drop_geometry())
# Plot general contribution for all observations
plot(var_contrib)
```
